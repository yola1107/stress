# 压测 QPS 与延迟说明

## 为何客户端优化对 QPS 提升有限？

当前 QPS ≈ 22.7K、延迟 ≈ 125ms 时，**主要瓶颈在游戏 API 服务端与网络**，不在本客户端。

### 关系式

```
QPS ≈ 并发请求数 / 单请求平均耗时(秒)
```

- 单请求耗时 **125ms** ≈ 网络 RTT + **游戏服务端处理时间**
- 客户端在发完请求后大部分时间在 **等待响应**，本地 CPU 占用很低
- 因此：**加大连接池、减少重试延迟等，对“等待响应”这段没有帮助**

### 客户端已做的优化

- HTTP 连接池、Keep-Alive、合理超时
- 不强制禁用 HTTP/2（HTTPS 时由 Go 默认协商，多路复用）
- 请求/响应 JSON 使用 jsoniter、Buffer 池化
- Session 重试与状态检查频率已调优

这些能减少连接建立、序列化等开销，但在 **125ms 里占比很小**，所以整体 QPS 提升有限。

## 如何显著提升 QPS？

### 1. 提高并发（最直接）

- 在任务配置里 **增加 Member 数量**（例如 3000 → 5000）
- 并发请求数上去，QPS 会线性增加，直到 **游戏服务端或网络成为瓶颈**

### 2. 降低单请求延迟（需动服务端/网络）

- **游戏 API 服务**：优化逻辑、DB/缓存、扩容
- **网络**：同机房/同可用区部署、专线
- 若 125ms 能降到 80ms，在相同并发下 QPS 约可提升 50%+

### 3. 确认是否在用 HTTP/2

- 本客户端已 **不再强制禁用 HTTP/2**（已去掉 `TLSNextProto` 覆盖）
- 若游戏 API 是 **HTTPS** 且服务端支持 HTTP/2，Go 会自动用 HTTP/2
- 可在抓包或服务端日志中确认：多路复用会减少连接数、有时能略降延迟

### 4. 用 pprof 确认瓶颈

```bash
# 压测时开 pprof
go run -cpuprofile=cpu.prof ./cmd/server
# 压测结束后
go tool pprof -http=:8080 cpu.prof
```

若 CPU 主要耗在 `net/http`、`read` 等，说明时间在 **等 IO**，瓶颈在服务端/网络；若耗在 JSON、业务逻辑，再针对性优化客户端。

## 小结

- **22.7K QPS、125ms 延迟** 下，瓶颈主要在 **游戏 API 响应时间与网络**。
- 客户端侧已做合理优化；要明显再提 QPS，需要：**加并发** 或 **降服务端/网络延迟**，必要时用 pprof 验证。
